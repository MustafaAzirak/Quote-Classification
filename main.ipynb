{
 "cells": [
  {
   "attachments": {
    "Ba%C5%9Fl%C4%B1ks%C4%B1z%20Diyagram.drawio%281%29.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "e04c8c4f",
   "metadata": {},
   "source": [
    "## NAME : Mustafa Azırak\n",
    "### ReadME infos about homework : \n",
    "\n",
    "### Quote Classification\n",
    "\n",
    "This project focuses on assigning relevant tags to quotes extracted from a dataset. The objective is to explore various problem transformation methods and classifier combinations to accurately predict multiple labels associated with quotes. By leveraging machine learning techniques, this endeavor aims to enhance the understanding and categorization of textual data, facilitating efficient organization and retrieval of information.\n",
    "\n",
    "#### Dataset\n",
    "\n",
    "The dataset comprises quotes along with their corresponding authors and tags. Quotes are extracted from a website and encompass a diverse range of topics and themes. Each quote may be associated with multiple tags, providing a rich source of textual data for multi-label classification.\n",
    "\n",
    "#### Project Workflow\n",
    "\n",
    "![Ba%C5%9Fl%C4%B1ks%C4%B1z%20Diyagram.drawio%281%29.png](attachment:Ba%C5%9Fl%C4%B1ks%C4%B1z%20Diyagram.drawio%281%29.png)\n",
    "<br>\n",
    "1. Data Scraping: Quotes, authors, and tags are extracted from a website using web scraping techniques. BeautifulSoup is utilized to parse HTML content and retrieve relevant information. Extracted data is organized into a DataFrame and saved for further analysis.<br>\n",
    "<br>\n",
    "2. Data Pre-Processing: Data undergoes cleaning, encoding, and feature selection to ensure its suitability for analysis and modeling. Text data is pre-processed to remove noise, standardize text, and extract meaningful features. Additionally, feature selection techniques are applied to identify the most relevant attributes for classification.<br>\n",
    "<br>\n",
    "3. Multi-Label Classification: Three problem transformation methods (One Vs Rest, Binary Relevance, and Classifier Chain) are explored in combination with various classifiers including Gaussian Naive Bayes, Logistic Regression, Random Forest, Support Vector Classifier (SVC), and K-Nearest Neighbors (KNN). These combinations are evaluated to determine the most effective approach for multi-label classification of quotes.<br>\n",
    "<br>\n",
    "4. Evaluation: The accuracy of different classifier-problem transformation combinations is evaluated and visualized using a bar plot. This evaluation aids in identifying the optimal approach for accurately predicting multiple labels associated with quotes.<br>\n",
    "\n",
    "#### Results\n",
    "\n",
    "The project concludes with insights into the most effective classifier-problem transformation combinations for multi-label classification of quotes. By leveraging machine learning techniques and exploring diverse methodologies, the project enhances the understanding and organization of textual data, facilitating efficient categorization and retrieval of information.\n",
    "\n",
    "#### Dependencies\n",
    "\n",
    "- Python 3\n",
    "- Pandas\n",
    "- BeautifulSoup\n",
    "- Scikit-learn\n",
    "- NLTK (Natural Language Toolkit)\n",
    "- Matplotlib\n",
    "\n",
    "###### Further details about the parts are given on every code block section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fb83c0",
   "metadata": {},
   "source": [
    "# Q&A\n",
    "\n",
    "### Scrape enough data\n",
    "#### How can you decide the data is enough?\n",
    "\n",
    "In addressing the task of Multi-Label Text Classification, my primary aim was to gather a diverse dataset to ensure the effectiveness of the classification models. Intuitively, I scraped data from a source, resulting in 100 distinct quotes, each accompanied by its author, tag, and link. This decision was rooted in the understanding that a wide-ranging dataset is essential for training models capable of recognizing various patterns across different tags. However, I recognized that merely having a large volume of data might not suffice. Factors such as the diversity of tags and the distribution of data among them also play crucial roles. Additionally, the inherent complexity of Multi-Label Text Classification further emphasized the need for a well-balanced dataset. While obtaining 100 quotes was a promising start, I acknowledged the necessity of balancing dataset size, diversity, and complexity to facilitate effective model training.\n",
    "\n",
    "#### Explain your thought process and do experiments)\n",
    "\n",
    "To assess the sufficiency of my dataset, I conducted experiments, including attempts to plot learning curves. Unfortunately, these experiments yielded empty or zero results, prompting me to delve deeper into the dataset's adequacy. I hypothesized that the small dataset size, in comparison to the high number of distinct tags, might be the underlying issue. In Multi-Label Text Classification, where examples can belong to multiple classes simultaneously, having a considerable number of examples for each class is crucial for effective model learning. The disparity between the dataset size and the multitude of tags presented a notable challenge. Despite encountering setbacks, I recognized the importance of exploring various techniques to evaluate data sufficiency. I remained open to potential solutions such as data augmentation and leveraging pre-trained models trained on larger datasets to mitigate the limitations posed by the dataset's size.\n",
    "\n",
    "#### How did you select the possible labels?\n",
    "\n",
    "When determining the labels for the classification task, I made strategic decisions regarding the dataset's structure. Specifically, I omitted irrelevant metadata such as the \"Link\" column from consideration, deeming it unnecessary for the classification task at hand. Additionally, I opted to concatenate the \"Quotes\" and \"Authors\" columns to form the input features for the models. This choice stemmed from my belief that the authors' names could provide valuable contextual information conducive to predicting tags associated with quotes accurately. By incorporating authors' names alongside quotes in the input features, I aimed to enrich the dataset's content and enhance the models' understanding of the relationships between quotes and their corresponding tags. However, I remained receptive to exploring alternative feature combinations to optimize the model's performance.\n",
    "\n",
    "### Convert text data into numeric data\n",
    "#### What are the options? (At most 1 sentence for each technique is enough)\n",
    "\n",
    "1. Bag-of-Words (BoW): Represents text data by counting the frequency of each word in the document and each document is represented by a vector where each element corresponds to the count of a specific word.\n",
    "\n",
    "2. Term Frequency-Inverse Document Frequency (TF-IDF): Weights the importance of each word in a document by considering its frequency within the document and across the entire corpus, it helps to highlight words that are more discriminative across documents.\n",
    "\n",
    "3. Word Embeddings (e.g., Word2Vec, GloVe): Represent words as dense vectors in a high-dimensional space, capturing semantic relationships between words and these embeddings are trained on large corpora and can capture context and similarity between words.\n",
    "\n",
    "#### Why did you choose your option ?\n",
    "\n",
    "I choose Term Frequency-Inverse Document Frequency (TF-IDF), because it effectively captures the importance of words in each quote while downweighting common terms across the entire dataset. TF-IDF allows the classification model to focus on distinguishing features relevant to the tags associated with each quote, thereby enhancing the accuracy of the classification task. Additionally, TF-IDF is suitable for this project as it enables the model to identify discriminative words that are indicative of specific tags, contributing to the effective classification of quotes.\n",
    "\n",
    "\n",
    "### Create a model\n",
    "#### How did you choose your model?\n",
    "\n",
    "1. Logistic Regression with One Vs Rest (OvR) Classifier:\n",
    "- One Vs Rest (OvR) strategy was employed with Logistic Regression as the base classifier.\n",
    "- Logistic Regression is chosen due to its simplicity, efficiency, and ability to handle binary classification tasks effectively. Moreover, it's a common choice for OvR strategy which works well for multi-label classification problems.\n",
    "\n",
    "2. Binary Relevance (BR) Strategy with Multiple Classifiers:\n",
    "- Binary Relevance strategy was applied with various classifiers including Gaussian Naive Bayes, Logistic Regression, Random Forest, Support Vector Classifier (SVC), and K-Nearest Neighbors (KNN).\n",
    "- Multiple classifiers were chosen to compare their performance under the BR strategy. Each classifier has its strengths and weaknesses, and testing them helps identify the most suitable one for the given task.\n",
    "\n",
    "3. Classifier Chain (CC) Strategy with Multiple Classifiers:\n",
    "- Classifier Chain strategy was employed with the same set of classifiers used under the BR strategy.\n",
    "- Similar to BR, CC was tested with multiple classifiers to evaluate their performance in capturing tag dependencies. CC considers tag dependencies, making it suitable for tasks where tag ordering matters.\n",
    "\n",
    "4. Label Powerset (LP) Strategy with Multiple Classifiers:\n",
    "- Label Powerset strategy was also tested with the same set of classifiers.\n",
    "- LP transforms the multi-label classification problem into a single-label problem, and each classifier predicts the presence of a unique combination of labels. LP helps capture complex relationships between labels.\n",
    "\n",
    "Model Selection Process:\n",
    "\n",
    "- The choice of models was guided by the characteristics of the task and the strategies employed for multi-label classification.\n",
    "- Logistic Regression, Gaussian Naive Bayes, and K-Nearest Neighbors are relatively simple models and were chosen for comparison purposes and as potential baseline models.\n",
    "- Random Forest and Support Vector Classifier (SVC) are more complex models known for their ability to capture non-linear relationships and were included to test their performance in this task.\n",
    "- By testing multiple models under different problem transformation strategies, the code aims to identify the most effective combination of model and strategy for accurately predicting multiple labels associated with quotes.\n",
    "\n",
    "### Train your model\n",
    "#### Can you train you models in different ways? What are the parameters?\n",
    "\n",
    "1. One Vs Rest (OvR) Classifier:\n",
    "\n",
    "This strategy involves training one classifier per class, with each classifier trained to distinguish between one class and all others.\n",
    "\n",
    "Parameters:\n",
    "- solver: It specifies the optimization algorithm used in the logistic regression model. The 'sag' solver stands for Stochastic Average Gradient descent, which is suitable for large datasets.\n",
    "- C (Inverse of regularization strength): Regularization helps prevent overfitting by penalizing large parameter values. The parameter 'C' controls the strength of regularization, where smaller values indicate stronger regularization.\n",
    "- Choosing the 'sag' solver is suitable for large datasets because it efficiently handles large-scale optimization problems by using stochastic gradient descent.\n",
    "- Adjusting the 'C' parameter allows controlling the balance between fitting the training data and preventing overfitting. Smaller values of 'C' increase regularization strength, which can help generalize the model better.\n",
    "\n",
    "2. Binary Relevance (BR) Classifier and Classifier Chain (CC) Classifier:\n",
    "\n",
    "Both strategies transform the multi-label classification problem into multiple binary classification problems, with each tag treated as a separate binary classification task.\n",
    "The classifiers used in these strategies (Gaussian Naive Bayes, Logistic Regression, Random Forest, SVC, KNN) have similar parameters.\n",
    "\n",
    "Parameters:\n",
    "- Regularization Parameters: Such as 'C' in Logistic Regression and 'kernel' and 'C' in SVC, control the regularization strength.\n",
    "- Number of Estimators: In the case of Random Forest, it represents the number of trees in the forest, which can affect model complexity and overfitting.\n",
    "- Nearest Neighbors: For KNN, the number of neighbors considered ('n_neighbors') and the distance metric ('metric') can significantly impact model performance.\n",
    "\n",
    "For Logistic Regression and SVC, tuning the 'C' parameter is crucial. A smaller 'C' value increases regularization strength, which can help prevent overfitting.\n",
    "In Random Forest, the 'n_estimators' parameter controls the number of trees in the forest. Increasing this parameter can lead to a more robust model, but it also increases computation time.\n",
    "For KNN, selecting an appropriate value for 'n_neighbors' is essential. Too few neighbors can lead to overfitting, while too many neighbors can lead to underfitting. Additionally, choosing the right distance metric ('metric') based on the data's characteristics is crucial for accurate predictions.\n",
    "\n",
    "3. Label Powerset (LP) Classifier:\n",
    "\n",
    "This strategy transforms the multi-label classification problem into a single-label problem by considering each unique label combination as a distinct class.\n",
    "\n",
    "The classifiers used with Label Powerset have similar parameters to those in Binary Relevance and Classifier Chain strategies.\n",
    "\n",
    "Parameters:\n",
    "- The regularization parameter 'C' in Logistic Regression and 'C' and 'kernel' in SVC play significant roles in controlling model complexity and overfitting.\n",
    "- In Random Forest, the 'n_estimators' parameter determines the number of trees in the forest, affecting the model's robustness.\n",
    "- For KNN, the choice of 'n_neighbors' and the distance metric ('metric') are crucial in determining the model's performance.\n",
    "\n",
    "\n",
    "### Evaluate your model\n",
    "\n",
    "Results:\n",
    "\n",
    "1. One-vs-Rest Logistic Regression:\n",
    "- Test accuracy for each tag ranges from approximately 0.83 to 1.0.\n",
    "\n",
    "This approach treats each tag as a separate binary classification problem. The reported accuracies indicate how well the model predicts each individual tag. Since each quote can have multiple tags, accuracy for a single tag doesn't fully represent model performance.\n",
    "\n",
    "2. Problem Transform: Binary Relevance:\n",
    "- Gaussian Naive Bayes: Accuracy = 0.0\n",
    "- Logistic Regression: Error occurred due to single-class data\n",
    "- Random Forest Classifier: Accuracy = 0.0\n",
    "- Support Vector Classifier (SVC): Error occurred due to single-class data\n",
    "- K Neighbors Classifier: Accuracy = 0.0333\n",
    "\n",
    "Binary Relevance transforms the multi-label problem into multiple binary classification problems (one for each tag). The reported accuracies reflect how well each tag is predicted independently. Again, accuracy for a single tag doesn't fully represent model performance.\n",
    "\n",
    "3. Problem Transform: Classifier Chain:\n",
    "- Gaussian Naive Bayes: Accuracy = 0.0\n",
    "- Logistic Regression: Error occurred due to single-class data\n",
    "- Random Forest Classifier: Accuracy = 0.0\n",
    "- Support Vector Classifier (SVC): Error occurred due to single-class data\n",
    "- K Neighbors Classifier: Accuracy = 0.0333\n",
    "\n",
    "Classifier Chain considers the correlation between tags by building a chain of classifiers, where each classifier uses the predictions of the previous ones as additional features. This approach can capture dependencies between tags. However, the reported accuracies still represent individual tag prediction performance.\n",
    "\n",
    "4. Problem Transform: Label Powerset:\n",
    "- Gaussian Naive Bayes: Accuracy = 0.0333\n",
    "- Logistic Regression: Accuracy = 0.0333\n",
    "- Random Forest Classifier: Accuracy = 0.0\n",
    "- Support Vector Classifier (SVC): Accuracy = 0.0333\n",
    "- K Neighbors Classifier: Accuracy = 0.0333\n",
    "\n",
    "Label Powerset transforms the multi-label problem into a multi-class problem, where each unique combination of tags becomes a distinct class. The reported accuracies represent how accurately the model predicts the entire set of tags for each quote.\n",
    "\n",
    "0.0 Accuracy: This means that the model's predictions for all labels are completely incorrect for every instance in the dataset. Essentially, the model is not able to correctly identify any of the labels associated with the text inputs. This could indicate severe underfitting or a fundamental problem with the model's architecture or training process.\n",
    "\n",
    "1.0 Accuracy: Conversely, achieving a 1.0 accuracy implies that the model's predictions perfectly match the true labels for every instance in the dataset. In other words, the model correctly identifies all the labels associated with each text input without making any mistakes. This is the ideal scenario and indicates that the model has learned the underlying patterns in the data extremely well.\n",
    "\n",
    "#### Explain what could you do better if you were given enough resources?\n",
    "If provided with ample resources, I would conduct extensive experiments on a larger dataset to gain deeper insights into the performance of various models. Utilizing techniques such as learning curve plotting would enable me to assess the sufficiency of the dataset and analyze model behavior more comprehensively. With a larger dataset, I anticipate achieving improved results across models due to increased data volume, facilitating better model training and evaluation.\n",
    "\n",
    "Moreover, in addition to Quotes and Authors, if I had access to more features, I would thoroughly analyze them to uncover correlations and patterns. This would enable me to conduct more robust feature selection processes, enhancing the quality and relevance of features used in modeling. By leveraging a broader range of features, I could potentially capture more nuanced relationships within the data, leading to more accurate and insightful model predictions.\n",
    "\n",
    "#### What improvements can be made on your project?\n",
    "\n",
    "- Enhance Data Collection: Expanding the dataset by gathering a larger and more diverse collection of quotes would be beneficial. This could involve scraping quotes from multiple sources or utilizing APIs to access a broader range of textual data.\n",
    "\n",
    "- Augment Existing Data: Introducing data augmentation techniques can help diversify the dataset further. For instance, paraphrasing existing quotes, introducing synonyms, or adding slight variations to the text could enrich the dataset without requiring additional manual effort.\n",
    "\n",
    "- Explore Advanced NLP Techniques: Using the advanced natural language processing (NLP) methodologies could significantly enhance the project's efficacy. Utilizing techniques like word embeddings or leveraging pre-trained language models can provide deeper insights into the semantic nuances of the quotes, thereby improving the model's understanding and performance.\n",
    "\n",
    "- Fine-Tune Model Parameters: Experimenting with various hyperparameter settings for the classifiers and problem transformation methods can lead to more optimal model performance. Techniques like grid search or randomized search can aid in identifying the most effective parameter configurations.\n",
    "\n",
    "- Address Class Imbalance: Handling any imbalance in the distribution of tags within the dataset is crucial. Techniques such as oversampling, undersampling, or adjusting class weights during training can ensure that the model learns from all classes equally, thereby improving its ability to generalize.\n",
    "\n",
    "- Feature Engineering: Exploring additional features, such as sentiment analysis, named entity recognition, or topic modeling, can provide richer context to the quotes and enhance the model's understanding of the underlying themes and concepts.\n",
    "\n",
    "- Utilize Ensemble Methods: Employing ensemble learning techniques, such as stacking or boosting, can leverage the collective wisdom of multiple classifiers to improve overall prediction accuracy and robustness.\n",
    "\n",
    "- Enhance Model Interpretability: Improving the interpretability of the models by analyzing feature importance, generating explanations for predictions, or visualizing decision boundaries can provide valuable insights into how the model makes its predictions.\n",
    "\n",
    "- Implement Cross-Validation: Applying cross-validation techniques can provide a more robust assessment of the model's performance and help mitigate overfitting issues.\n",
    "\n",
    "- Optimize Code Efficiency: Identifying opportunities for optimization, such as optimizing loops, utilizing vectorized operations, or parallelizing computations, can enhance the efficiency of the codebase and reduce runtime.\n",
    "\n",
    "#### Where could you use such a project? Please give 2 examples...\n",
    "\n",
    "1. Blog or Article Recommendation Systems: Imagine a website that offers a variety of articles and blog posts on different topics like technology, travel, health, and more. With this project, the website can automatically categorize each article based on its content. When a user reads an article, the system can recommend similar articles from the same category or with related topics. This helps users discover content they're interested in more easily, making their experience more enjoyable.\n",
    "\n",
    "2. Social Media Content Filtering: Social media platforms have millions of users posting content every day. To keep the platform safe and enjoyable for everyone, the platform needs to filter out inappropriate or harmful content. This project can help by automatically tagging posts or comments with relevant labels, like \"funny,\" \"inspirational,\" \"educational,\" or \"spam.\" By doing this, the platform can quickly identify and remove harmful content while promoting positive and engaging posts for users to see.\n",
    "\n",
    "#### Write a short summary to explain the decisions you had to make during the development.\n",
    "\n",
    "1. Data Scraping and Preprocessing:\n",
    "- Choice of Source: The decision to scrape quotes from the website \"http://quotes.toscrape.com\" was made to obtain a diverse range of textual data for classification.\n",
    "- Data Structure: Quotes, authors, and tags were extracted and organized into a DataFrame, with the unnecessary \"Link\" column dropped.\n",
    "- Cleaning and Encoding: Missing values in the \"Tags\" column were handled by dropping corresponding rows, and tags were encoded using one-hot encoding to prepare the data for classification.\n",
    "- Feature Selection: The \"Quotes\" and \"Authors\" columns were merged into a single column, \"Quote_Author,\" to enrich the context, and unnecessary columns were dropped.\n",
    "\n",
    "2. Text Data Preprocessing:\n",
    "- Cleaning: Text data underwent cleaning operations, including converting to lowercase, removing HTML tags, punctuation, and special characters, and retaining only alphabetical characters.\n",
    "- Removing Stop Words: A set of stop words was defined and removed from the text data to focus on meaningful content.\n",
    "- Stemming: Words were stemmed using the SnowballStemmer to reduce them to their root forms and improve consistency.\n",
    "\n",
    "3. Train-Test Split and Feature Extraction:\n",
    "- Splitting Data: The dataset was split into training and testing sets to train models and evaluate their performance.\n",
    "- Feature Extraction: TF-IDF vectorization was applied to transform text data into numerical features, capturing the importance of words while downweighting common terms across the corpus.\n",
    "\n",
    "4. Multi-Label Classification:\n",
    "- Problem Transformation: Three problem transformation methods (One Vs Rest, Binary Relevance, Classifier Chain) were explored to handle the complexity of multi-label classification.\n",
    "- Choice of Classifiers: Various classifiers including Gaussian Naive Bayes, Logistic Regression, Random Forest, SVC, and KNN were evaluated under each problem transformation method to determine their effectiveness.\n",
    "\n",
    "5. Evaluation:\n",
    "- Assessment of Accuracy: Accuracy scores were calculated for each classifier under different problem transformation methods, and the results were visualized using a bar plot to identify the optimal classifier-problem transformation combinations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8ed6b5",
   "metadata": {},
   "source": [
    "# 1. Data Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea1461e",
   "metadata": {},
   "source": [
    "##### In this section I extract quotes, authors, tags, and URLs from the website \"http://quotes.toscrape.com\". This script navigate through multiple pages of the website's HTML content, parsing relevant information such as quotes and author details using BeautifulSoup. The extracted data is then organized into a DataFrame and saved as a CSV file named \"Quotes.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "def8a202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jovian\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df86ca0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraping_quotes(number_of_pages,path=None):\n",
    "    if path is None:\n",
    "        path='Quotes.csv'\n",
    "    items=parse_quotes(number_of_pages)    \n",
    "    df=pd.DataFrame(items)\n",
    "    df.to_csv(path,index=None)\n",
    "    print('Quotes information for {} pages written to file \"{}\"'.format(number_of_pages,path))\n",
    "    return path\n",
    "\n",
    "\n",
    "def parse_quotes(number_of_pages):\n",
    "    subject_names,urls,author_names,quotes_list=[],[],[],[]\n",
    "    for i in range(1,number_of_pages+1):\n",
    "        page=str(i)\n",
    "        quote_doc=get_webpage(page)\n",
    "        div_tags=quote_doc.find_all('div',class_='quote')\n",
    "        subject_names.extend(get_quote_tag(div_tags)) \n",
    "        urls.extend(get_author_urls(div_tags))         \n",
    "        author_names.extend(get_author_name(div_tags)) \n",
    "        quotes_list.extend(get_quotes(div_tags))       \n",
    "        Quotes_list=list_of_dict(quotes_list,author_names,urls,subject_names)\n",
    "    return Quotes_list\n",
    "\n",
    "def get_quotes(div_tags):\n",
    "    quotes=[]\n",
    "    for tag in div_tags:\n",
    "        quote=tag.find('span',class_='text').text\n",
    "        quotes.append(quote)\n",
    "    return quotes\n",
    "\n",
    "def get_author_urls(div_tags):\n",
    "    author_links=[]\n",
    "    for tag in div_tags:\n",
    "        span_tag=tag.find('span',class_=None)\n",
    "        author_link='http://quotes.toscrape.com'+span_tag.find('a')['href']\n",
    "        author_links.append(author_link)\n",
    "    return author_links\n",
    "\n",
    "def get_quote_tag(div_tags):\n",
    "    name_tags=[]\n",
    "    for tag in div_tags:\n",
    "        name_tag=tag.find('div',class_='tags').meta['content']\n",
    "        name_tags.append(name_tag)\n",
    "    return name_tags\n",
    "\n",
    "def get_author_name(div_tags):\n",
    "    authors=[]\n",
    "    for tag in div_tags:\n",
    "        span_tag=tag.find('span',class_=None)\n",
    "    #print(span_tag)\n",
    "        author=span_tag.find('small',class_='author').text\n",
    "        authors.append(author)\n",
    "    return authors \n",
    "\n",
    "\n",
    "def list_of_dict(quotes_list,author_names,urls,subject_names):\n",
    "    return [{'Quotes': quotes_list[i],\n",
    "             'Author': author_names[i],\n",
    "             'Tags': subject_names[i],\n",
    "             'Link': urls[i]} for i in range(len(quotes_list))]\n",
    "\n",
    "def get_webpage(page):\n",
    "    url='http://quotes.toscrape.com/page/'+page+'/'\n",
    "\n",
    "    response=requests.get(url)\n",
    "\n",
    "    if response.status_code!=200:\n",
    "        print('Status Code:',response.status_code)\n",
    "        raise Exception ('We Failed to fetch the webpage')+url \n",
    "    else:\n",
    "        doc=BeautifulSoup(response.text,'html.parser')\n",
    "    return doc             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee65b113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quotes information for 10 pages written to file \"Quotes.csv\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Quotes.csv'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scraping_quotes(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a5cc752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quotes</th>\n",
       "      <th>Author</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“The world as we have created it is a process ...</td>\n",
       "      <td>Albert Einstein</td>\n",
       "      <td>change,deep-thoughts,thinking,world</td>\n",
       "      <td>http://quotes.toscrape.com/author/Albert-Einstein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>“It is our choices, Harry, that show what we t...</td>\n",
       "      <td>J.K. Rowling</td>\n",
       "      <td>abilities,choices</td>\n",
       "      <td>http://quotes.toscrape.com/author/J-K-Rowling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>“There are only two ways to live your life. On...</td>\n",
       "      <td>Albert Einstein</td>\n",
       "      <td>inspirational,life,live,miracle,miracles</td>\n",
       "      <td>http://quotes.toscrape.com/author/Albert-Einstein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>“The person, be it gentleman or lady, who has ...</td>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>aliteracy,books,classic,humor</td>\n",
       "      <td>http://quotes.toscrape.com/author/Jane-Austen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>“Imperfection is beauty, madness is genius and...</td>\n",
       "      <td>Marilyn Monroe</td>\n",
       "      <td>be-yourself,inspirational</td>\n",
       "      <td>http://quotes.toscrape.com/author/Marilyn-Monroe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>“You never really understand a person until yo...</td>\n",
       "      <td>Harper Lee</td>\n",
       "      <td>better-life-empathy</td>\n",
       "      <td>http://quotes.toscrape.com/author/Harper-Lee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>“You have to write the book that wants to be w...</td>\n",
       "      <td>Madeleine L'Engle</td>\n",
       "      <td>books,children,difficult,grown-ups,write,write...</td>\n",
       "      <td>http://quotes.toscrape.com/author/Madeleine-LE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>“Never tell the truth to people who are not wo...</td>\n",
       "      <td>Mark Twain</td>\n",
       "      <td>truth</td>\n",
       "      <td>http://quotes.toscrape.com/author/Mark-Twain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>“A person's a person, no matter how small.”</td>\n",
       "      <td>Dr. Seuss</td>\n",
       "      <td>inspirational</td>\n",
       "      <td>http://quotes.toscrape.com/author/Dr-Seuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>“... a mind needs books as a sword needs a whe...</td>\n",
       "      <td>George R.R. Martin</td>\n",
       "      <td>books,mind</td>\n",
       "      <td>http://quotes.toscrape.com/author/George-R-R-M...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Quotes              Author  \\\n",
       "0   “The world as we have created it is a process ...     Albert Einstein   \n",
       "1   “It is our choices, Harry, that show what we t...        J.K. Rowling   \n",
       "2   “There are only two ways to live your life. On...     Albert Einstein   \n",
       "3   “The person, be it gentleman or lady, who has ...         Jane Austen   \n",
       "4   “Imperfection is beauty, madness is genius and...      Marilyn Monroe   \n",
       "..                                                ...                 ...   \n",
       "95  “You never really understand a person until yo...          Harper Lee   \n",
       "96  “You have to write the book that wants to be w...   Madeleine L'Engle   \n",
       "97  “Never tell the truth to people who are not wo...          Mark Twain   \n",
       "98        “A person's a person, no matter how small.”           Dr. Seuss   \n",
       "99  “... a mind needs books as a sword needs a whe...  George R.R. Martin   \n",
       "\n",
       "                                                 Tags  \\\n",
       "0                 change,deep-thoughts,thinking,world   \n",
       "1                                   abilities,choices   \n",
       "2            inspirational,life,live,miracle,miracles   \n",
       "3                       aliteracy,books,classic,humor   \n",
       "4                           be-yourself,inspirational   \n",
       "..                                                ...   \n",
       "95                                better-life-empathy   \n",
       "96  books,children,difficult,grown-ups,write,write...   \n",
       "97                                              truth   \n",
       "98                                      inspirational   \n",
       "99                                         books,mind   \n",
       "\n",
       "                                                 Link  \n",
       "0   http://quotes.toscrape.com/author/Albert-Einstein  \n",
       "1       http://quotes.toscrape.com/author/J-K-Rowling  \n",
       "2   http://quotes.toscrape.com/author/Albert-Einstein  \n",
       "3       http://quotes.toscrape.com/author/Jane-Austen  \n",
       "4    http://quotes.toscrape.com/author/Marilyn-Monroe  \n",
       "..                                                ...  \n",
       "95       http://quotes.toscrape.com/author/Harper-Lee  \n",
       "96  http://quotes.toscrape.com/author/Madeleine-LE...  \n",
       "97       http://quotes.toscrape.com/author/Mark-Twain  \n",
       "98         http://quotes.toscrape.com/author/Dr-Seuss  \n",
       "99  http://quotes.toscrape.com/author/George-R-R-M...  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_main = pd.read_csv(\"Quotes.csv\")\n",
    "df_main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00276bf6",
   "metadata": {},
   "source": [
    "# 2. Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93c7a95",
   "metadata": {},
   "source": [
    "### 2.1 Cleaning and Encoding Data\n",
    "\n",
    "##### I perform preprocessing tasks on the DataFrame df_main to ensure data quality and prepare it for further analysis. It begins by dropping the \"Link\" column from the DataFrame. Following this, a custom function check_missing_values() is defined to identify and report missing values and empty strings in specified columns. The function is then applied to check for missing values in columns \"Quotes\", \"Author\", and \"Tags\". Missing values in the \"Tags\" column are dropped from the DataFrame using dropna(). The tags are tokenized and lowercased, followed by encoding categorical data using one-hot encoding with MultiLabelBinarizer from scikit-learn. The encoded tags are concatenated with the original DataFrame and the original \"Tags\" column is dropped. Finally, the preprocessed DataFrame is displayed, containing cleaned and encoded data ready for further analysis or modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8a31d63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quotes</th>\n",
       "      <th>Author</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“The world as we have created it is a process ...</td>\n",
       "      <td>Albert Einstein</td>\n",
       "      <td>change,deep-thoughts,thinking,world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>“It is our choices, Harry, that show what we t...</td>\n",
       "      <td>J.K. Rowling</td>\n",
       "      <td>abilities,choices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>“There are only two ways to live your life. On...</td>\n",
       "      <td>Albert Einstein</td>\n",
       "      <td>inspirational,life,live,miracle,miracles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>“The person, be it gentleman or lady, who has ...</td>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>aliteracy,books,classic,humor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>“Imperfection is beauty, madness is genius and...</td>\n",
       "      <td>Marilyn Monroe</td>\n",
       "      <td>be-yourself,inspirational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>“You never really understand a person until yo...</td>\n",
       "      <td>Harper Lee</td>\n",
       "      <td>better-life-empathy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>“You have to write the book that wants to be w...</td>\n",
       "      <td>Madeleine L'Engle</td>\n",
       "      <td>books,children,difficult,grown-ups,write,write...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>“Never tell the truth to people who are not wo...</td>\n",
       "      <td>Mark Twain</td>\n",
       "      <td>truth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>“A person's a person, no matter how small.”</td>\n",
       "      <td>Dr. Seuss</td>\n",
       "      <td>inspirational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>“... a mind needs books as a sword needs a whe...</td>\n",
       "      <td>George R.R. Martin</td>\n",
       "      <td>books,mind</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Quotes              Author  \\\n",
       "0   “The world as we have created it is a process ...     Albert Einstein   \n",
       "1   “It is our choices, Harry, that show what we t...        J.K. Rowling   \n",
       "2   “There are only two ways to live your life. On...     Albert Einstein   \n",
       "3   “The person, be it gentleman or lady, who has ...         Jane Austen   \n",
       "4   “Imperfection is beauty, madness is genius and...      Marilyn Monroe   \n",
       "..                                                ...                 ...   \n",
       "95  “You never really understand a person until yo...          Harper Lee   \n",
       "96  “You have to write the book that wants to be w...   Madeleine L'Engle   \n",
       "97  “Never tell the truth to people who are not wo...          Mark Twain   \n",
       "98        “A person's a person, no matter how small.”           Dr. Seuss   \n",
       "99  “... a mind needs books as a sword needs a whe...  George R.R. Martin   \n",
       "\n",
       "                                                 Tags  \n",
       "0                 change,deep-thoughts,thinking,world  \n",
       "1                                   abilities,choices  \n",
       "2            inspirational,life,live,miracle,miracles  \n",
       "3                       aliteracy,books,classic,humor  \n",
       "4                           be-yourself,inspirational  \n",
       "..                                                ...  \n",
       "95                                better-life-empathy  \n",
       "96  books,children,difficult,grown-ups,write,write...  \n",
       "97                                              truth  \n",
       "98                                      inspirational  \n",
       "99                                         books,mind  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_main = df_main.drop(\"Link\", axis=1)\n",
    "df_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b46205f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of NaN values in 'Quotes': 0\n",
      "Number of empty strings in 'Quotes': 0\n",
      "\n",
      "Number of NaN values in 'Author': 0\n",
      "Number of empty strings in 'Author': 0\n",
      "\n",
      "Number of NaN values in 'Tags': 3\n",
      "Number of empty strings in 'Tags': 0\n"
     ]
    }
   ],
   "source": [
    "def check_missing_values(df, column_name):\n",
    "    nan_values = df[column_name].isna().sum()\n",
    "    empty_strings = (df[column_name] == '').sum()\n",
    "    rows_with_missing_values = df[df[column_name].isna() | (df[column_name] == '')]\n",
    "    print(f\"\\nNumber of NaN values in '{column_name}': {nan_values}\")\n",
    "    print(f\"Number of empty strings in '{column_name}': {empty_strings}\")\n",
    "\n",
    "check_missing_values(df_main, \"Quotes\")\n",
    "check_missing_values(df_main, \"Author\")\n",
    "check_missing_values(df_main, \"Tags\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5616cc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = df_main.dropna(subset=[\"Tags\"])\n",
    "\n",
    "df_main.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1dbfcbd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['change,deep-thoughts,thinking,world', 'abilities,choices',\n",
       "       'inspirational,life,live,miracle,miracles',\n",
       "       'aliteracy,books,classic,humor', 'be-yourself,inspirational',\n",
       "       'adulthood,success,value', 'life,love',\n",
       "       'edison,failure,inspirational,paraphrased',\n",
       "       'misattributed-eleanor-roosevelt', 'humor,obvious,simile',\n",
       "       'friends,heartbreak,inspirational,life,love,sisters',\n",
       "       'courage,friends', 'simplicity,understand', 'love', 'fantasy',\n",
       "       'life,navigation',\n",
       "       'activism,apathy,hate,indifference,inspirational,love,opposite,philosophy',\n",
       "       'friendship,lack-of-friendship,lack-of-love,love,marriage,unhappy-marriage',\n",
       "       'books,contentment,friends,friendship,life',\n",
       "       'fate,life,misattributed-john-lennon,planning,plans',\n",
       "       'love,poetry', 'happiness', 'attributed-no-source',\n",
       "       'humor,religion', 'humor', 'comedy,life,yourself',\n",
       "       'children,fairy-tales', 'imagination', 'music',\n",
       "       'learning,reading,seuss', 'dumbledore', 'friendship',\n",
       "       'misattributed-to-mother-teresa,paraphrased',\n",
       "       'death,inspirational', 'chocolate,food,humor',\n",
       "       'misattributed-to-c-s-lewis,reading',\n",
       "       'knowledge,learning,understanding,wisdom', 'books,library',\n",
       "       'inspirational', 'read,readers,reading,reading-books',\n",
       "       'books,inspirational,reading,tea', 'girls,love', 'life,simile',\n",
       "       'hope,inspirational', 'friendship,love',\n",
       "       'attributed,fear,inspiration', 'books,thought',\n",
       "       'misattributed-to-einstein', 'drug,romance,simile',\n",
       "       'books,friends,novelist-quotes', 'inspirational,life,yourself',\n",
       "       'alcohol', 'the-hunger-games',\n",
       "       'bilbo,journey,lost,quest,travel,wander', 'live-death-love',\n",
       "       'good,writing', 'life,regrets', 'education', 'troubles',\n",
       "       'humor,open-mind,thinking', 'humor,philosophy',\n",
       "       'authors,books,literature,reading,writing',\n",
       "       'humor,insanity,lies,lying,self-indulgence,truth',\n",
       "       'beatles,connection,dreamers,dreaming,dreams,hope,inspirational,peace',\n",
       "       'humor,sinister', 'books,classic,reading', 'mistakes',\n",
       "       'humor,love,romantic,women', 'integrity', 'books,library,reading',\n",
       "       'elizabeth-bennet,jane-austen', 'age,fairytales,growing-up', 'god',\n",
       "       'death,life', 'misattributed-mark-twain,truth',\n",
       "       'christianity,faith,religion,sun', 'truth', 'adventure,love',\n",
       "       'courage', 'life', 'better-life-empathy',\n",
       "       'books,children,difficult,grown-ups,write,writers,writing',\n",
       "       'books,mind'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_main[\"Tags\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1016001f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       97\n",
       "unique      83\n",
       "top       love\n",
       "freq         4\n",
       "Name: Tags, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_main[\"Tags\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebcb1bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\musta\\AppData\\Local\\Temp\\ipykernel_4328\\1552479755.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Tags\"] = df[\"Tags\"].apply(lambda x: x.split(','))\n",
      "C:\\Users\\musta\\AppData\\Local\\Temp\\ipykernel_4328\\1552479755.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Tags\"] = df[\"Tags\"].apply(lambda x: [tag.lower() for tag in x])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quotes</th>\n",
       "      <th>Author</th>\n",
       "      <th>abilities</th>\n",
       "      <th>activism</th>\n",
       "      <th>adulthood</th>\n",
       "      <th>adventure</th>\n",
       "      <th>age</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>aliteracy</th>\n",
       "      <th>apathy</th>\n",
       "      <th>...</th>\n",
       "      <th>unhappy-marriage</th>\n",
       "      <th>value</th>\n",
       "      <th>wander</th>\n",
       "      <th>wisdom</th>\n",
       "      <th>women</th>\n",
       "      <th>world</th>\n",
       "      <th>write</th>\n",
       "      <th>writers</th>\n",
       "      <th>writing</th>\n",
       "      <th>yourself</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“The world as we have created it is a process ...</td>\n",
       "      <td>Albert Einstein</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>“It is our choices, Harry, that show what we t...</td>\n",
       "      <td>J.K. Rowling</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>“There are only two ways to live your life. On...</td>\n",
       "      <td>Albert Einstein</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>“The person, be it gentleman or lady, who has ...</td>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>“Imperfection is beauty, madness is genius and...</td>\n",
       "      <td>Marilyn Monroe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>“You never really understand a person until yo...</td>\n",
       "      <td>Harper Lee</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>“You have to write the book that wants to be w...</td>\n",
       "      <td>Madeleine L'Engle</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>“Never tell the truth to people who are not wo...</td>\n",
       "      <td>Mark Twain</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>“A person's a person, no matter how small.”</td>\n",
       "      <td>Dr. Seuss</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>“... a mind needs books as a sword needs a whe...</td>\n",
       "      <td>George R.R. Martin</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97 rows × 139 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Quotes              Author  \\\n",
       "0   “The world as we have created it is a process ...     Albert Einstein   \n",
       "1   “It is our choices, Harry, that show what we t...        J.K. Rowling   \n",
       "2   “There are only two ways to live your life. On...     Albert Einstein   \n",
       "3   “The person, be it gentleman or lady, who has ...         Jane Austen   \n",
       "4   “Imperfection is beauty, madness is genius and...      Marilyn Monroe   \n",
       "..                                                ...                 ...   \n",
       "92  “You never really understand a person until yo...          Harper Lee   \n",
       "93  “You have to write the book that wants to be w...   Madeleine L'Engle   \n",
       "94  “Never tell the truth to people who are not wo...          Mark Twain   \n",
       "95        “A person's a person, no matter how small.”           Dr. Seuss   \n",
       "96  “... a mind needs books as a sword needs a whe...  George R.R. Martin   \n",
       "\n",
       "    abilities  activism  adulthood  adventure  age  alcohol  aliteracy  \\\n",
       "0           0         0          0          0    0        0          0   \n",
       "1           1         0          0          0    0        0          0   \n",
       "2           0         0          0          0    0        0          0   \n",
       "3           0         0          0          0    0        0          1   \n",
       "4           0         0          0          0    0        0          0   \n",
       "..        ...       ...        ...        ...  ...      ...        ...   \n",
       "92          0         0          0          0    0        0          0   \n",
       "93          0         0          0          0    0        0          0   \n",
       "94          0         0          0          0    0        0          0   \n",
       "95          0         0          0          0    0        0          0   \n",
       "96          0         0          0          0    0        0          0   \n",
       "\n",
       "    apathy  ...  unhappy-marriage  value  wander  wisdom  women  world  write  \\\n",
       "0        0  ...                 0      0       0       0      0      1      0   \n",
       "1        0  ...                 0      0       0       0      0      0      0   \n",
       "2        0  ...                 0      0       0       0      0      0      0   \n",
       "3        0  ...                 0      0       0       0      0      0      0   \n",
       "4        0  ...                 0      0       0       0      0      0      0   \n",
       "..     ...  ...               ...    ...     ...     ...    ...    ...    ...   \n",
       "92       0  ...                 0      0       0       0      0      0      0   \n",
       "93       0  ...                 0      0       0       0      0      0      1   \n",
       "94       0  ...                 0      0       0       0      0      0      0   \n",
       "95       0  ...                 0      0       0       0      0      0      0   \n",
       "96       0  ...                 0      0       0       0      0      0      0   \n",
       "\n",
       "    writers  writing  yourself  \n",
       "0         0        0         0  \n",
       "1         0        0         0  \n",
       "2         0        0         0  \n",
       "3         0        0         0  \n",
       "4         0        0         0  \n",
       "..      ...      ...       ...  \n",
       "92        0        0         0  \n",
       "93        1        1         0  \n",
       "94        0        0         0  \n",
       "95        0        0         0  \n",
       "96        0        0         0  \n",
       "\n",
       "[97 rows x 139 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "df = df_main\n",
    "\n",
    "df[\"Tags\"] = df[\"Tags\"].apply(lambda x: x.split(','))\n",
    "\n",
    "df[\"Tags\"] = df[\"Tags\"].apply(lambda x: [tag.lower() for tag in x])\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "tags_encoded = pd.DataFrame(mlb.fit_transform(df['Tags']), columns=mlb.classes_, index=df.index)\n",
    "\n",
    "df = pd.concat([df, tags_encoded], axis=1)\n",
    "\n",
    "df.drop(\"Tags\", axis=1, inplace=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d4fe2d",
   "metadata": {},
   "source": [
    "### 2.2 Feature Selection\n",
    "\n",
    "##### I merge the \"Quotes\" and \"Author\" columns into a single column called \"Quote_Author\" to provide enriched context. This consolidation aims to enhance the interpretability of the data. Subsequently, unnecessary columns are removed, and the \"Quote_Author\" column is positioned as the first column in the DataFrame. Additionally, a list of tags is extracted from the DataFrame's column names, excluding the \"Quote_Author\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2baa6e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Quote_Author\"] = df[\"Quotes\"] + ' - ' + df[\"Author\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e527901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quote_Author</th>\n",
       "      <th>abilities</th>\n",
       "      <th>activism</th>\n",
       "      <th>adulthood</th>\n",
       "      <th>adventure</th>\n",
       "      <th>age</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>aliteracy</th>\n",
       "      <th>apathy</th>\n",
       "      <th>attributed</th>\n",
       "      <th>...</th>\n",
       "      <th>unhappy-marriage</th>\n",
       "      <th>value</th>\n",
       "      <th>wander</th>\n",
       "      <th>wisdom</th>\n",
       "      <th>women</th>\n",
       "      <th>world</th>\n",
       "      <th>write</th>\n",
       "      <th>writers</th>\n",
       "      <th>writing</th>\n",
       "      <th>yourself</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“The world as we have created it is a process ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>“It is our choices, Harry, that show what we t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>“There are only two ways to live your life. On...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>“The person, be it gentleman or lady, who has ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>“Imperfection is beauty, madness is genius and...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>“You never really understand a person until yo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>“You have to write the book that wants to be w...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>“Never tell the truth to people who are not wo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>“A person's a person, no matter how small.” - ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>“... a mind needs books as a sword needs a whe...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97 rows × 138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Quote_Author  abilities  activism  \\\n",
       "0   “The world as we have created it is a process ...          0         0   \n",
       "1   “It is our choices, Harry, that show what we t...          1         0   \n",
       "2   “There are only two ways to live your life. On...          0         0   \n",
       "3   “The person, be it gentleman or lady, who has ...          0         0   \n",
       "4   “Imperfection is beauty, madness is genius and...          0         0   \n",
       "..                                                ...        ...       ...   \n",
       "92  “You never really understand a person until yo...          0         0   \n",
       "93  “You have to write the book that wants to be w...          0         0   \n",
       "94  “Never tell the truth to people who are not wo...          0         0   \n",
       "95  “A person's a person, no matter how small.” - ...          0         0   \n",
       "96  “... a mind needs books as a sword needs a whe...          0         0   \n",
       "\n",
       "    adulthood  adventure  age  alcohol  aliteracy  apathy  attributed  ...  \\\n",
       "0           0          0    0        0          0       0           0  ...   \n",
       "1           0          0    0        0          0       0           0  ...   \n",
       "2           0          0    0        0          0       0           0  ...   \n",
       "3           0          0    0        0          1       0           0  ...   \n",
       "4           0          0    0        0          0       0           0  ...   \n",
       "..        ...        ...  ...      ...        ...     ...         ...  ...   \n",
       "92          0          0    0        0          0       0           0  ...   \n",
       "93          0          0    0        0          0       0           0  ...   \n",
       "94          0          0    0        0          0       0           0  ...   \n",
       "95          0          0    0        0          0       0           0  ...   \n",
       "96          0          0    0        0          0       0           0  ...   \n",
       "\n",
       "    unhappy-marriage  value  wander  wisdom  women  world  write  writers  \\\n",
       "0                  0      0       0       0      0      1      0        0   \n",
       "1                  0      0       0       0      0      0      0        0   \n",
       "2                  0      0       0       0      0      0      0        0   \n",
       "3                  0      0       0       0      0      0      0        0   \n",
       "4                  0      0       0       0      0      0      0        0   \n",
       "..               ...    ...     ...     ...    ...    ...    ...      ...   \n",
       "92                 0      0       0       0      0      0      0        0   \n",
       "93                 0      0       0       0      0      0      1        1   \n",
       "94                 0      0       0       0      0      0      0        0   \n",
       "95                 0      0       0       0      0      0      0        0   \n",
       "96                 0      0       0       0      0      0      0        0   \n",
       "\n",
       "    writing  yourself  \n",
       "0         0         0  \n",
       "1         0         0  \n",
       "2         0         0  \n",
       "3         0         0  \n",
       "4         0         0  \n",
       "..      ...       ...  \n",
       "92        0         0  \n",
       "93        1         0  \n",
       "94        0         0  \n",
       "95        0         0  \n",
       "96        0         0  \n",
       "\n",
       "[97 rows x 138 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=[\"Quotes\", \"Author\"], inplace=True)\n",
    "df.insert(0, \"Quote_Author\", df.pop(\"Quote_Author\"))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b865ad81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abilities', 'activism', 'adulthood', 'adventure', 'age', 'alcohol', 'aliteracy', 'apathy', 'attributed', 'attributed-no-source', 'authors', 'be-yourself', 'beatles', 'better-life-empathy', 'bilbo', 'books', 'change', 'children', 'chocolate', 'choices', 'christianity', 'classic', 'comedy', 'connection', 'contentment', 'courage', 'death', 'deep-thoughts', 'difficult', 'dreamers', 'dreaming', 'dreams', 'drug', 'dumbledore', 'edison', 'education', 'elizabeth-bennet', 'failure', 'fairy-tales', 'fairytales', 'faith', 'fantasy', 'fate', 'fear', 'food', 'friends', 'friendship', 'girls', 'god', 'good', 'growing-up', 'grown-ups', 'happiness', 'hate', 'heartbreak', 'hope', 'humor', 'imagination', 'indifference', 'insanity', 'inspiration', 'inspirational', 'integrity', 'jane-austen', 'journey', 'knowledge', 'lack-of-friendship', 'lack-of-love', 'learning', 'library', 'lies', 'life', 'literature', 'live', 'live-death-love', 'lost', 'love', 'lying', 'marriage', 'mind', 'miracle', 'miracles', 'misattributed-eleanor-roosevelt', 'misattributed-john-lennon', 'misattributed-mark-twain', 'misattributed-to-c-s-lewis', 'misattributed-to-einstein', 'misattributed-to-mother-teresa', 'mistakes', 'music', 'navigation', 'novelist-quotes', 'obvious', 'open-mind', 'opposite', 'paraphrased', 'peace', 'philosophy', 'planning', 'plans', 'poetry', 'quest', 'read', 'readers', 'reading', 'reading-books', 'regrets', 'religion', 'romance', 'romantic', 'self-indulgence', 'seuss', 'simile', 'simplicity', 'sinister', 'sisters', 'success', 'sun', 'tea', 'the-hunger-games', 'thinking', 'thought', 'travel', 'troubles', 'truth', 'understand', 'understanding', 'unhappy-marriage', 'value', 'wander', 'wisdom', 'women', 'world', 'write', 'writers', 'writing', 'yourself']\n"
     ]
    }
   ],
   "source": [
    "tags = list(df.columns.values)\n",
    "tags = tags[1:]\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8798002",
   "metadata": {},
   "source": [
    "### 2.3 Text Data Preprocessing\n",
    "\n",
    "##### I perform various text cleaning operations on the \"Quote_Author\" column of the DataFrame. This includes converting text to lowercase, removing HTML tags, cleaning punctuation and special characters, and retaining only alphabetical characters. These preprocessing steps are essential for preparing text data for analysis or modeling tasks in natural language processing (NLP). By standardizing the text and removing noise, the data becomes more suitable for the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc9b7ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import re\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e5ee64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanHtml(sentence):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, ' ', str(sentence))\n",
    "    return cleantext\n",
    "\n",
    "\n",
    "def cleanPunc(sentence):\n",
    "    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
    "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
    "    cleaned = cleaned.strip()\n",
    "    cleaned = cleaned.replace(\"\\n\",\" \")\n",
    "    return cleaned\n",
    "\n",
    "\n",
    "def keepAlpha(sentence):\n",
    "    alpha_sent = \"\"\n",
    "    for word in sentence.split():\n",
    "        alpha_word = re.sub('[^a-z A-Z]+', ' ', word)\n",
    "        alpha_sent += alpha_word\n",
    "        alpha_sent += \" \"\n",
    "    alpha_sent = alpha_sent.strip()\n",
    "    return alpha_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90614a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quote_Author</th>\n",
       "      <th>abilities</th>\n",
       "      <th>activism</th>\n",
       "      <th>adulthood</th>\n",
       "      <th>adventure</th>\n",
       "      <th>age</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>aliteracy</th>\n",
       "      <th>apathy</th>\n",
       "      <th>attributed</th>\n",
       "      <th>...</th>\n",
       "      <th>unhappy-marriage</th>\n",
       "      <th>value</th>\n",
       "      <th>wander</th>\n",
       "      <th>wisdom</th>\n",
       "      <th>women</th>\n",
       "      <th>world</th>\n",
       "      <th>write</th>\n",
       "      <th>writers</th>\n",
       "      <th>writing</th>\n",
       "      <th>yourself</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the world as we have created it is a process o...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it is our choices harry that show what we trul...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>there are only two ways to live your life one ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the person be it gentleman or lady who has not...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>imperfection is beauty madness is genius and i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Quote_Author  abilities  activism  \\\n",
       "0  the world as we have created it is a process o...          0         0   \n",
       "1  it is our choices harry that show what we trul...          1         0   \n",
       "2  there are only two ways to live your life one ...          0         0   \n",
       "3  the person be it gentleman or lady who has not...          0         0   \n",
       "4  imperfection is beauty madness is genius and i...          0         0   \n",
       "\n",
       "   adulthood  adventure  age  alcohol  aliteracy  apathy  attributed  ...  \\\n",
       "0          0          0    0        0          0       0           0  ...   \n",
       "1          0          0    0        0          0       0           0  ...   \n",
       "2          0          0    0        0          0       0           0  ...   \n",
       "3          0          0    0        0          1       0           0  ...   \n",
       "4          0          0    0        0          0       0           0  ...   \n",
       "\n",
       "   unhappy-marriage  value  wander  wisdom  women  world  write  writers  \\\n",
       "0                 0      0       0       0      0      1      0        0   \n",
       "1                 0      0       0       0      0      0      0        0   \n",
       "2                 0      0       0       0      0      0      0        0   \n",
       "3                 0      0       0       0      0      0      0        0   \n",
       "4                 0      0       0       0      0      0      0        0   \n",
       "\n",
       "   writing  yourself  \n",
       "0        0         0  \n",
       "1        0         0  \n",
       "2        0         0  \n",
       "3        0         0  \n",
       "4        0         0  \n",
       "\n",
       "[5 rows x 138 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Quote_Author\"] = df[\"Quote_Author\"].str.lower()\n",
    "df[\"Quote_Author\"] = df[\"Quote_Author\"].apply(cleanHtml)\n",
    "df[\"Quote_Author\"] = df[\"Quote_Author\"].apply(cleanPunc)\n",
    "df[\"Quote_Author\"] = df[\"Quote_Author\"].apply(keepAlpha)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb116bc",
   "metadata": {},
   "source": [
    "### 2.4 Removing Stop Words\n",
    "\n",
    "##### I define a set of English stop words, expanding it to include numerical words and common terms. Stop words, such as articles and prepositions, often appear frequently in text but typically do not carry significant meaning for analysis purposes. I then compile a regular expression pattern to identify and remove these stop words from the \"Quote_Author\" column of the DataFrame. By eliminating these words, I aim to focus the text data on meaningful content and improving the quality of subsequent analysis tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7851a785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quote_Author</th>\n",
       "      <th>abilities</th>\n",
       "      <th>activism</th>\n",
       "      <th>adulthood</th>\n",
       "      <th>adventure</th>\n",
       "      <th>age</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>aliteracy</th>\n",
       "      <th>apathy</th>\n",
       "      <th>attributed</th>\n",
       "      <th>...</th>\n",
       "      <th>unhappy-marriage</th>\n",
       "      <th>value</th>\n",
       "      <th>wander</th>\n",
       "      <th>wisdom</th>\n",
       "      <th>women</th>\n",
       "      <th>world</th>\n",
       "      <th>write</th>\n",
       "      <th>writers</th>\n",
       "      <th>writing</th>\n",
       "      <th>yourself</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>world    created    process   thinking  canno...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>choices harry  show   truly  far    abiliti...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ways  live  life    though nothing   mirac...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>person   gentleman  lady    pleasure   good n...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>imperfection  beauty madness  genius   better ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Quote_Author  abilities  activism  \\\n",
       "0   world    created    process   thinking  canno...          0         0   \n",
       "1     choices harry  show   truly  far    abiliti...          1         0   \n",
       "2      ways  live  life    though nothing   mirac...          0         0   \n",
       "3   person   gentleman  lady    pleasure   good n...          0         0   \n",
       "4  imperfection  beauty madness  genius   better ...          0         0   \n",
       "\n",
       "   adulthood  adventure  age  alcohol  aliteracy  apathy  attributed  ...  \\\n",
       "0          0          0    0        0          0       0           0  ...   \n",
       "1          0          0    0        0          0       0           0  ...   \n",
       "2          0          0    0        0          0       0           0  ...   \n",
       "3          0          0    0        0          1       0           0  ...   \n",
       "4          0          0    0        0          0       0           0  ...   \n",
       "\n",
       "   unhappy-marriage  value  wander  wisdom  women  world  write  writers  \\\n",
       "0                 0      0       0       0      0      1      0        0   \n",
       "1                 0      0       0       0      0      0      0        0   \n",
       "2                 0      0       0       0      0      0      0        0   \n",
       "3                 0      0       0       0      0      0      0        0   \n",
       "4                 0      0       0       0      0      0      0        0   \n",
       "\n",
       "   writing  yourself  \n",
       "0        0         0  \n",
       "1        0         0  \n",
       "2        0         0  \n",
       "3        0         0  \n",
       "4        0         0  \n",
       "\n",
       "[5 rows x 138 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.update(['zero','one','two','three','four','five','six','seven','eight','nine','ten','may','also','across','among','beside','however','yet','within'])\n",
    "re_stop_words = re.compile(r\"\\b(\" + \"|\".join(stop_words) + \")\\\\W\", re.I)\n",
    "def removeStopWords(sentence):\n",
    "    global re_stop_words\n",
    "    return re_stop_words.sub(\" \", sentence)\n",
    "\n",
    "df[\"Quote_Author\"] = df[\"Quote_Author\"].apply(removeStopWords)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2a0ea5",
   "metadata": {},
   "source": [
    "### 2.5 Stemming\n",
    "\n",
    "##### I utilize the SnowballStemmer from the NLTK library to reduce words to their root or base form. Stemming helps to normalize text data by removing suffixes and prefixes, thereby consolidating variations of words into a single form. I apply the stemming process to the \"Quote_Author\" column of the DataFrame, iterating through each word and stemming it using the SnowballStemmer. By doing so, I aim to further refine the text data and improve its consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b96760b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quote_Author</th>\n",
       "      <th>abilities</th>\n",
       "      <th>activism</th>\n",
       "      <th>adulthood</th>\n",
       "      <th>adventure</th>\n",
       "      <th>age</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>aliteracy</th>\n",
       "      <th>apathy</th>\n",
       "      <th>attributed</th>\n",
       "      <th>...</th>\n",
       "      <th>unhappy-marriage</th>\n",
       "      <th>value</th>\n",
       "      <th>wander</th>\n",
       "      <th>wisdom</th>\n",
       "      <th>women</th>\n",
       "      <th>world</th>\n",
       "      <th>write</th>\n",
       "      <th>writers</th>\n",
       "      <th>writing</th>\n",
       "      <th>yourself</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>world creat process think cannot chang without...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>choic harri show truli far abil j k rowl</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>way live life though noth miracl though everyt...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>person gentleman ladi pleasur good novel must ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>imperfect beauti mad genius better absolut rid...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Quote_Author  abilities  activism  \\\n",
       "0  world creat process think cannot chang without...          0         0   \n",
       "1           choic harri show truli far abil j k rowl          1         0   \n",
       "2  way live life though noth miracl though everyt...          0         0   \n",
       "3  person gentleman ladi pleasur good novel must ...          0         0   \n",
       "4  imperfect beauti mad genius better absolut rid...          0         0   \n",
       "\n",
       "   adulthood  adventure  age  alcohol  aliteracy  apathy  attributed  ...  \\\n",
       "0          0          0    0        0          0       0           0  ...   \n",
       "1          0          0    0        0          0       0           0  ...   \n",
       "2          0          0    0        0          0       0           0  ...   \n",
       "3          0          0    0        0          1       0           0  ...   \n",
       "4          0          0    0        0          0       0           0  ...   \n",
       "\n",
       "   unhappy-marriage  value  wander  wisdom  women  world  write  writers  \\\n",
       "0                 0      0       0       0      0      1      0        0   \n",
       "1                 0      0       0       0      0      0      0        0   \n",
       "2                 0      0       0       0      0      0      0        0   \n",
       "3                 0      0       0       0      0      0      0        0   \n",
       "4                 0      0       0       0      0      0      0        0   \n",
       "\n",
       "   writing  yourself  \n",
       "0        0         0  \n",
       "1        0         0  \n",
       "2        0         0  \n",
       "3        0         0  \n",
       "4        0         0  \n",
       "\n",
       "[5 rows x 138 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "def stemming(sentence):\n",
    "    stemSentence = \"\"\n",
    "    for word in sentence.split():\n",
    "        stem = stemmer.stem(word)\n",
    "        stemSentence += stem\n",
    "        stemSentence += \" \"\n",
    "    stemSentence = stemSentence.strip()\n",
    "    return stemSentence\n",
    "\n",
    "df[\"Quote_Author\"] = df[\"Quote_Author\"].apply(stemming)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3d3d05",
   "metadata": {},
   "source": [
    "### 2.6 Train-Test Split\n",
    "\n",
    "##### I use scikit-learn's train_test_split function to divide the DataFrame into training and testing sets. With a specified test size of 30% and a random state set to 42 for reproducibility, I ensure a representative distribution of samples by shuffling the data. Extracting the text data from these subsets, I prepare them for further analysis and modeling. This partitioning strategy allows for training machine learning models on one subset and evaluating their performance on another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19efef4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67, 138)\n",
      "(30, 138)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, random_state=42, test_size=0.30, shuffle=True)\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62ceb0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = train[\"Quote_Author\"]\n",
    "test_text = test[\"Quote_Author\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42337881",
   "metadata": {},
   "source": [
    "### 2.7 Feature Extraction (TF-IDF)\n",
    "\n",
    "##### I utilize the TfidfVectorizer from scikit-learn to transform the text data into numerical features. This process applies the TF-IDF (Term Frequency-Inverse Document Frequency) technique, which assigns weights to each word based on its frequency in the document and across the corpus. By setting parameters such as strip_accents='unicode', analyzer='word', and ngram_range=(1,3), I ensure proper text preprocessing and consider unigrams, bigrams, and trigrams for feature generation. \n",
    "\n",
    "##### The TF-IDF technique is particularly suitable for my NLP project, which involves classifying quotes based on tags. With a dataset of 100 quotes containing tags and authors, TF-IDF helps capture the importance of words in each quote while downweighting common terms across all quotes. This approach enables the classification model to focus on distinguishing features relevant to the tags associated with each quote, enhancing the accuracy of the classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d12eea3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(ngram_range=(1, 3), strip_accents='unicode')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(strip_accents='unicode', analyzer='word', ngram_range=(1,3), norm='l2')\n",
    "vectorizer.fit(train_text)\n",
    "vectorizer.fit(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4fdcac27",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = vectorizer.transform(train_text)\n",
    "y_train = train.drop(labels = \"Quote_Author\", axis=1)\n",
    "\n",
    "x_test = vectorizer.transform(test_text)\n",
    "y_test = test.drop(labels = \"Quote_Author\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa59363f",
   "metadata": {},
   "source": [
    "# 3. Multi-Label Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eddbcee",
   "metadata": {},
   "source": [
    "### 3.1 Multiple Binary Classifications - (One Vs Rest Classifier)\n",
    "\n",
    "#####  I implement the One Vs Rest (OvR) strategy using logistic regression for multi-label classification. This approach allows me to handle multiple tags simultaneously by treating each tag as a separate binary classification task. \n",
    "\n",
    "##### The One Vs Rest Classifier constructs a separate classifier for each tag, where the positive class includes instances with the respective tag and the negative class includes instances without that tag. By training individual classifiers for each tag, the model can effectively capture the complex relationships between quotes and their associated tags. This strategy enables the model to predict the presence or absence of each tag independently, providing flexibility and scalability for multi-label classification tasks. Through this iterative process, I evaluate the performance of logistic regression models for each tag, calculating test accuracy to assess the model's ability to correctly classify quotes based on their associated tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19716f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Processing abilities tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing activism tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing adulthood tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing adventure tags...**\n",
      "Test accuracy is 0.9666666666666667\n",
      "\n",
      "\n",
      "**Processing age tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing alcohol tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing aliteracy tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing apathy tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing attributed tags...**\n",
      "Test accuracy is 0.9666666666666667\n",
      "\n",
      "\n",
      "**Processing attributed-no-source tags...**\n",
      "Test accuracy is 0.9333333333333333\n",
      "\n",
      "\n",
      "**Processing authors tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing be-yourself tags...**\n",
      "Test accuracy is 0.9666666666666667\n",
      "\n",
      "\n",
      "**Processing beatles tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing better-life-empathy tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing bilbo tags...**\n",
      "Test accuracy is 0.9666666666666667\n",
      "\n",
      "\n",
      "**Processing books tags...**\n",
      "Test accuracy is 0.8666666666666667\n",
      "\n",
      "\n",
      "**Processing change tags...**\n",
      "Test accuracy is 0.9666666666666667\n",
      "\n",
      "\n",
      "**Processing children tags...**\n",
      "Test accuracy is 0.9333333333333333\n",
      "\n",
      "\n",
      "**Processing chocolate tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing choices tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing christianity tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing classic tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing comedy tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing connection tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing contentment tags...**\n",
      "Test accuracy is 0.9666666666666667\n",
      "\n",
      "\n",
      "**Processing courage tags...**\n",
      "Test accuracy is 0.9666666666666667\n",
      "\n",
      "\n",
      "**Processing death tags...**\n",
      "Test accuracy is 0.9666666666666667\n",
      "\n",
      "\n",
      "**Processing deep-thoughts tags...**\n",
      "Test accuracy is 0.9666666666666667\n",
      "\n",
      "\n",
      "**Processing difficult tags...**\n",
      "Test accuracy is 0.9666666666666667\n",
      "\n",
      "\n",
      "**Processing dreamers tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing dreaming tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing dreams tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing drug tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing dumbledore tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing edison tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing education tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing elizabeth-bennet tags...**\n",
      "Test accuracy is 0.9666666666666667\n",
      "\n",
      "\n",
      "**Processing failure tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing fairy-tales tags...**\n",
      "Test accuracy is 0.9666666666666667\n",
      "\n",
      "\n",
      "**Processing fairytales tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing faith tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing fantasy tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing fate tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing fear tags...**\n",
      "Test accuracy is 0.9666666666666667\n",
      "\n",
      "\n",
      "**Processing food tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing friends tags...**\n",
      "Test accuracy is 0.9\n",
      "\n",
      "\n",
      "**Processing friendship tags...**\n",
      "Test accuracy is 0.9\n",
      "\n",
      "\n",
      "**Processing girls tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing god tags...**\n",
      "Test accuracy is 0.9666666666666667\n",
      "\n",
      "\n",
      "**Processing good tags...**\n",
      "Test accuracy is 0.9666666666666667\n",
      "\n",
      "\n",
      "**Processing growing-up tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing grown-ups tags...**\n",
      "Test accuracy is 0.9666666666666667\n",
      "\n",
      "\n",
      "**Processing happiness tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing hate tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing heartbreak tags...**\n",
      "Test accuracy is 0.9666666666666667\n",
      "\n",
      "\n",
      "**Processing hope tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing humor tags...**\n",
      "Test accuracy is 0.8666666666666667\n",
      "\n",
      "\n",
      "**Processing imagination tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing indifference tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing insanity tags...**\n",
      "Test accuracy is 0.9666666666666667\n",
      "\n",
      "\n",
      "**Processing inspiration tags...**\n",
      "Test accuracy is 0.9666666666666667\n",
      "\n",
      "\n",
      "**Processing inspirational tags...**\n",
      "Test accuracy is 0.8666666666666667\n",
      "\n",
      "\n",
      "**Processing integrity tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing jane-austen tags...**\n",
      "Test accuracy is 0.9666666666666667\n",
      "\n",
      "\n",
      "**Processing journey tags...**\n",
      "Test accuracy is 0.9666666666666667\n",
      "\n",
      "\n",
      "**Processing knowledge tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing lack-of-friendship tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing lack-of-love tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing learning tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing library tags...**\n",
      "Test accuracy is 0.9666666666666667\n",
      "\n",
      "\n",
      "**Processing lies tags...**\n",
      "Test accuracy is 0.9666666666666667\n",
      "\n",
      "\n",
      "**Processing life tags...**\n",
      "Test accuracy is 0.8333333333333334\n",
      "\n",
      "\n",
      "**Processing literature tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing live tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing live-death-love tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing lost tags...**\n",
      "Test accuracy is 0.9666666666666667\n",
      "\n",
      "\n",
      "**Processing love tags...**\n",
      "Test accuracy is 0.8666666666666667\n",
      "\n",
      "\n",
      "**Processing lying tags...**\n",
      "Test accuracy is 0.9666666666666667\n",
      "\n",
      "\n",
      "**Processing marriage tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing mind tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing miracle tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing miracles tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing misattributed-eleanor-roosevelt tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing misattributed-john-lennon tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing misattributed-mark-twain tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing misattributed-to-c-s-lewis tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing misattributed-to-einstein tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing misattributed-to-mother-teresa tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing mistakes tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing music tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing navigation tags...**\n",
      "Test accuracy is 0.9666666666666667\n",
      "\n",
      "\n",
      "**Processing novelist-quotes tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing obvious tags...**\n",
      "Test accuracy is 0.9666666666666667\n",
      "\n",
      "\n",
      "**Processing open-mind tags...**\n",
      "Test accuracy is 0.9666666666666667\n",
      "\n",
      "\n",
      "**Processing opposite tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing paraphrased tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing peace tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing philosophy tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing planning tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing plans tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing poetry tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing quest tags...**\n",
      "Test accuracy is 0.9666666666666667\n",
      "\n",
      "\n",
      "**Processing read tags...**\n",
      "Test accuracy is 0.9666666666666667\n",
      "\n",
      "\n",
      "**Processing readers tags...**\n",
      "Test accuracy is 0.9666666666666667\n",
      "\n",
      "\n",
      "**Processing reading tags...**\n",
      "Test accuracy is 0.9\n",
      "\n",
      "\n",
      "**Processing reading-books tags...**\n",
      "Test accuracy is 0.9666666666666667\n",
      "\n",
      "\n",
      "**Processing regrets tags...**\n",
      "Test accuracy is 0.9666666666666667\n",
      "\n",
      "\n",
      "**Processing religion tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing romance tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing romantic tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing self-indulgence tags...**\n",
      "Test accuracy is 0.9666666666666667\n",
      "\n",
      "\n",
      "**Processing seuss tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing simile tags...**\n",
      "Test accuracy is 0.9333333333333333\n",
      "\n",
      "\n",
      "**Processing simplicity tags...**\n",
      "Test accuracy is 0.9666666666666667\n",
      "\n",
      "\n",
      "**Processing sinister tags...**\n",
      "Test accuracy is 0.9666666666666667\n",
      "\n",
      "\n",
      "**Processing sisters tags...**\n",
      "Test accuracy is 0.9666666666666667\n",
      "\n",
      "\n",
      "**Processing success tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing sun tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing tea tags...**\n",
      "Test accuracy is 0.9666666666666667\n",
      "\n",
      "\n",
      "**Processing the-hunger-games tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing thinking tags...**\n",
      "Test accuracy is 0.9333333333333333\n",
      "\n",
      "\n",
      "**Processing thought tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing travel tags...**\n",
      "Test accuracy is 0.9666666666666667\n",
      "\n",
      "\n",
      "**Processing troubles tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing truth tags...**\n",
      "Test accuracy is 0.9666666666666667\n",
      "\n",
      "\n",
      "**Processing understand tags...**\n",
      "Test accuracy is 0.9666666666666667\n",
      "\n",
      "\n",
      "**Processing understanding tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing unhappy-marriage tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing value tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing wander tags...**\n",
      "Test accuracy is 0.9666666666666667\n",
      "\n",
      "\n",
      "**Processing wisdom tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing women tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n",
      "**Processing world tags...**\n",
      "Test accuracy is 0.9666666666666667\n",
      "\n",
      "\n",
      "**Processing write tags...**\n",
      "Test accuracy is 0.9666666666666667\n",
      "\n",
      "\n",
      "**Processing writers tags...**\n",
      "Test accuracy is 0.9666666666666667\n",
      "\n",
      "\n",
      "**Processing writing tags...**\n",
      "Test accuracy is 0.9333333333333333\n",
      "\n",
      "\n",
      "**Processing yourself tags...**\n",
      "Test accuracy is 1.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "LogReg_pipeline = Pipeline([\n",
    "                ('clf', OneVsRestClassifier(LogisticRegression(solver='sag'), n_jobs=-1)),\n",
    "            ])\n",
    "\n",
    "for tag in tags:\n",
    "    print('**Processing {} tags...**'.format(tag))\n",
    "\n",
    "    LogReg_pipeline.fit(x_train, train[tag])\n",
    "\n",
    "    prediction = LogReg_pipeline.predict(x_test)\n",
    "    print('Test accuracy is {}'.format(accuracy_score(test[tag], prediction)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3753fa96",
   "metadata": {},
   "source": [
    "### 3.2 Multiple Binary Classifications - (Binary Relevance)\n",
    "\n",
    "##### I explore the Binary Relevance (BR) strategy for multi-label classification using various classifiers. The BR strategy treats each tag as a separate binary classification problem, independent of other tags. It achieves this by training a separate classifier for each tag, where the presence or absence of that tag is predicted. Here, I employ classifiers such as Gaussian Naive Bayes, Logistic Regression, Random Forest, Support Vector Classifier (SVC), and K-Nearest Neighbors (KNN) within the BinaryRelevance wrapper from the scikit-multilearn library. This wrapper transforms the multi-label classification problem into multiple binary classification problems, allowing for the application of traditional classifiers. By iterating through each classifier, training, predicting, and evaluating accuracy on the test set, I assess the performance of each classifier under the BR strategy. This approach enables the model to handle the complexity of multi-label classification tasks by independently predicting the presence or absence of each tag for a given quote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "24a6ce8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Problem Transform: BinaryRelevance, Classifier: GaussianNB\n",
      "Accuracy =  0.0\n",
      "\n",
      "\n",
      "Using Problem Transform: BinaryRelevance, Classifier: LogisticRegression\n",
      "Error occurred: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0\n",
      "\n",
      "\n",
      "Using Problem Transform: BinaryRelevance, Classifier: RandomForestClassifier\n",
      "Accuracy =  0.0\n",
      "\n",
      "\n",
      "Using Problem Transform: BinaryRelevance, Classifier: SVC\n",
      "Error occurred: The number of classes has to be greater than one; got 1 class\n",
      "\n",
      "\n",
      "Using Problem Transform: BinaryRelevance, Classifier: KNeighborsClassifier\n",
      "Accuracy =  0.03333333333333333\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "classifiers = [\n",
    "    GaussianNB(), LogisticRegression(), RandomForestClassifier(),\n",
    "    SVC(), KNeighborsClassifier()\n",
    "]\n",
    "\n",
    "BR_accuracy_data = {}\n",
    "\n",
    "for classifier in classifiers:\n",
    "    try:\n",
    "        print(f\"Using Problem Transform: BinaryRelevance, Classifier: {classifier.__class__.__name__}\")\n",
    "\n",
    "        pt_classifier = BinaryRelevance(classifier)\n",
    "\n",
    "        pt_classifier.fit(x_train, y_train)\n",
    "\n",
    "        predictions = pt_classifier.predict(x_test)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        print(\"Accuracy = \", accuracy)\n",
    "        print(\"\\n\")\n",
    "\n",
    "        BR_accuracy_data[classifier.__class__.__name__] = accuracy\n",
    "\n",
    "    except Exception as e:\n",
    "        BR_accuracy_data[classifier.__class__.__name__] = 0\n",
    "        print(f\"Error occurred: {str(e)}\")\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1c158a",
   "metadata": {},
   "source": [
    "### 3.3 Multiple Binary Classifications - (Classifier Chain)\n",
    "\n",
    "##### I explore the Classifier Chain (CC) strategy for multi-label classification using various classifiers. The CC strategy extends the Binary Relevance approach by considering the dependencies between tags. It constructs a chain of classifiers, where each classifier is trained to predict the presence of a tag while also considering the predictions of preceding classifiers in the chain. Here, I utilize classifiers such as Gaussian Naive Bayes, Logistic Regression, Random Forest, Support Vector Classifier (SVC), and K-Nearest Neighbors (KNN) within the ClassifierChain wrapper from the scikit-multilearn library. By iterating through each classifier, training, predicting, and evaluating accuracy on the test set, I assess the performance of each classifier under the CC strategy. This approach allows the model to capture the correlations between tags and improve prediction accuracy by incorporating information from previous predictions in the chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65965448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Problem Transform: ClassifierChain, Classifier: GaussianNB\n",
      "Accuracy =  0.0\n",
      "\n",
      "\n",
      "Using Problem Transform: ClassifierChain, Classifier: LogisticRegression\n",
      "Error occurred: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0\n",
      "\n",
      "\n",
      "Using Problem Transform: ClassifierChain, Classifier: RandomForestClassifier\n",
      "Accuracy =  0.0\n",
      "\n",
      "\n",
      "Using Problem Transform: ClassifierChain, Classifier: SVC\n",
      "Error occurred: The number of classes has to be greater than one; got 1 class\n",
      "\n",
      "\n",
      "Using Problem Transform: ClassifierChain, Classifier: KNeighborsClassifier\n",
      "Accuracy =  0.03333333333333333\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "classifiers = [\n",
    "    GaussianNB(), LogisticRegression(), RandomForestClassifier(),\n",
    "    SVC(), KNeighborsClassifier()\n",
    "]\n",
    "\n",
    "CC_accuracy_data = {}\n",
    "\n",
    "for classifier in classifiers:\n",
    "    try:\n",
    "        print(f\"Using Problem Transform: ClassifierChain, Classifier: {classifier.__class__.__name__}\")\n",
    "\n",
    "        pt_classifier = ClassifierChain(classifier)\n",
    "\n",
    "        pt_classifier.fit(x_train, y_train)\n",
    "\n",
    "        predictions = pt_classifier.predict(x_test)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        print(\"Accuracy = \", accuracy)\n",
    "        print(\"\\n\")\n",
    "\n",
    "        CC_accuracy_data[classifier.__class__.__name__] = accuracy\n",
    "\n",
    "    except Exception as e:\n",
    "        CC_accuracy_data[classifier.__class__.__name__] = 0\n",
    "        print(f\"Error occurred: {str(e)}\")\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9559dc01",
   "metadata": {},
   "source": [
    "### 3.4 Multiple Binary Classifications - (Label Powerset)\n",
    "\n",
    "##### I explore the Label Powerset (LP) strategy for multi-label classification using various classifiers. The LP strategy transforms the multi-label classification problem into a single-label problem by considering each unique combination of labels as a distinct class. It constructs a separate classifier for each unique label combination, allowing for the prediction of multiple labels simultaneously. Here, I utilize classifiers such as Gaussian Naive Bayes, Logistic Regression, Random Forest, Support Vector Classifier (SVC), and K-Nearest Neighbors (KNN) within the LabelPowerset wrapper from the scikit-multilearn library. By iterating through each classifier, training, predicting, and evaluating accuracy on the test set, I assess the performance of each classifier under the LP strategy. This approach enables the model to handle the complexity of multi-label classification tasks by treating each label combination as a separate class, thus capturing the relationships between different labels more effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2a0f176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Problem Transform: LabelPowerset, Classifier: GaussianNB\n",
      "Accuracy =  0.03333333333333333\n",
      "\n",
      "\n",
      "Using Problem Transform: LabelPowerset, Classifier: LogisticRegression\n",
      "Accuracy =  0.03333333333333333\n",
      "\n",
      "\n",
      "Using Problem Transform: LabelPowerset, Classifier: RandomForestClassifier\n",
      "Accuracy =  0.0\n",
      "\n",
      "\n",
      "Using Problem Transform: LabelPowerset, Classifier: SVC\n",
      "Accuracy =  0.03333333333333333\n",
      "\n",
      "\n",
      "Using Problem Transform: LabelPowerset, Classifier: KNeighborsClassifier\n",
      "Accuracy =  0.03333333333333333\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "classifiers = [\n",
    "    GaussianNB(), LogisticRegression(), RandomForestClassifier(),\n",
    "    SVC(), KNeighborsClassifier()\n",
    "]\n",
    "\n",
    "LP_accuracy_data = {}\n",
    "\n",
    "for classifier in classifiers:\n",
    "    try:\n",
    "        print(f\"Using Problem Transform: LabelPowerset, Classifier: {classifier.__class__.__name__}\")\n",
    "\n",
    "        pt_classifier = LabelPowerset(classifier)\n",
    "\n",
    "        pt_classifier.fit(x_train, y_train)\n",
    "\n",
    "        predictions = pt_classifier.predict(x_test)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        print(\"Accuracy = \", accuracy)\n",
    "        print(\"\\n\")\n",
    "\n",
    "        LP_accuracy_data[classifier.__class__.__name__] = accuracy\n",
    "\n",
    "    except Exception as e:\n",
    "        LP_accuracy_data[classifier.__class__.__name__] = 0\n",
    "        print(f\"Error occurred: {str(e)}\")\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9826b46b",
   "metadata": {},
   "source": [
    "# 4. Evaluation (Classifier - Problem Transformation)\n",
    "\n",
    "##### I evaluate various combinations of classifiers and problem transformation methods for multi-label classification. The plot illustrates the accuracy of different classifier-problem transformation combinations, considering problem transformation methods such as Binary Relevance, Classifier Chain, and Label Powerset, along with classifiers including Gaussian Naive Bayes, Logistic Regression, Random Forest, Support Vector Classifier (SVC), and K-Nearest Neighbors (KNN). Each bar in the plot represents the accuracy achieved by a specific classifier under a particular problem transformation method. By visualizing these accuracies, I can identify the most effective combination of classifier and problem transformation method for accurately predicting multiple labels associated with quotes in the dataset. This evaluation aids in selecting the optimal approach for multi-label classification in the context of the project's goals and requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84120db1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "problem_transforms = ['BinaryRelevance', 'ClassifierChain', 'LabelPowerset']\n",
    "classifiers = ['GaussianNB', 'LogisticRegression', 'RandomForest', 'SVC', 'KNeighborsClassifier']\n",
    "\n",
    "accuracies = {\n",
    "    'BinaryRelevance': BR_accuracy_data,\n",
    "    'ClassifierChain': CC_accuracy_data,\n",
    "    'LabelPowerset': LP_accuracy_data\n",
    "}\n",
    "\n",
    "for pt_method, acc_data in accuracies.items():\n",
    "    for classifier in classifiers:\n",
    "        if classifier not in acc_data:\n",
    "            acc_data[classifier] = 0.0\n",
    "\n",
    "bar_width = 0.15\n",
    "index = np.arange(len(classifiers))\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "for i, pt_method in enumerate(problem_transforms):\n",
    "    accuracies_for_method = [accuracies[pt_method][classifier_name] for classifier_name in classifiers]\n",
    "    plt.bar(index + i * bar_width, accuracies_for_method, bar_width, label=pt_method)\n",
    "\n",
    "plt.xlabel('Classifiers')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy of Different Classifier-Problem Transformation Combinations')\n",
    "plt.xticks(index + bar_width * 1.5, classifiers)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
